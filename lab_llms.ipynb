{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9sGjEWSy1FrY"
      },
      "source": [
        "# Large Language Models Lab\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nGJkS1ctKNvq"
      },
      "source": [
        "**NOTE:** You're only meant to change code marked with \"# TODO:\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fEKMx87cR105"
      },
      "source": [
        "## Table of Contents\n",
        "\n",
        "1. **Setting Up**\n",
        "    - API Key Configuration\n",
        "    - Connecting to OpenAI API\n",
        "2. **Exploring the API**\n",
        "    - Creating Chat Completions\n",
        "    - Understanding Completion Parameters\n",
        "3. **Prompt Engineering**\n",
        "    - Crafting Effective Prompts\n",
        "    - Strategies and Best Practices\n",
        "4. **Advanced Techniques**\n",
        "    - Utilizing Embeddings\n",
        "    - Function Calling in LLMs\n",
        "5. **Extras**\n",
        "    - Creating an API key\n",
        "    - Local Development with LLMs\n",
        "    - Context Windows\n",
        "    - Fine-Tuning LLMs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pSiOx5S_DYlf"
      },
      "source": [
        "## Part 0: Setup\n",
        "To be able to use OpenAI one needs to configure an API key to the be allowed responses to requests. Remember not to commit this key to any repository or upload it as OpenAI will disable the key if it is found, and others can use it to make requests that you or your organisation (Cogito) will pay for."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "LlRpazpLEtP2",
        "tags": [],
        "outputId": "16db9c70-6119-43b6-b09b-5370a1b4341a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-1.35.1-py3-none-any.whl (326 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/326.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━\u001b[0m \u001b[32m225.3/326.8 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m \u001b[32m317.4/326.8 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m326.8/326.8 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.7.3)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.6.2)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.18.4)\n",
            "Installing collected packages: h11, httpcore, httpx, openai\n",
            "Successfully installed h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 openai-1.35.1\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.25.2)\n",
            "Collecting python-dotenv\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Installing collected packages: python-dotenv\n",
            "Successfully installed python-dotenv-1.0.1\n"
          ]
        }
      ],
      "source": [
        "%pip install openai\n",
        "%pip install numpy\n",
        "%pip install python-dotenv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Laq8ql09DtyE",
        "tags": [],
        "outputId": "421e5062-1853-4539-fa4e-8df69ac04cb7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[SUCCESS] API Key is configured correctly.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "\n",
        "# Once you add your API key below, make sure to not share it with anyone! The API key should remain private.\n",
        "OPENAI_API_KEY: str = userdata.get(\"OPENAI_API_KEY_Ironhack\")\n",
        "\n",
        "# There are many different models to try out \"gpt-4\", \"gpt-4-turbo-preview\", \"gpt-3.5-turbo\"\n",
        "MODEL_NAME: str = \"gpt-3.5-turbo\"\n",
        "\n",
        "if not OPENAI_API_KEY:\n",
        "  print(\"[ERROR] The key is not configured correctly\")\n",
        "else:\n",
        "  print(\"[SUCCESS] API Key is configured correctly.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "AJ7gr0Q81D-a",
        "tags": []
      },
      "outputs": [],
      "source": [
        "from openai import OpenAI\n",
        "\n",
        "client = OpenAI(\n",
        "  api_key=OPENAI_API_KEY,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PrJPFSSqDWgw"
      },
      "source": [
        "## Part 1: API Connections"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Mj506eumJEMT",
        "tags": [],
        "outputId": "30ec58a6-7e08-4302-96c0-68a6653d3235",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Answer for the language model \n",
            "ChatCompletion(id='chatcmpl-9cC1cJ6TAIJ4aPTWNXVlQnnkbp5rd', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='In realms where the AI beasts roam,\\nLarge Language Models find a home.\\nThey parse and they predict,\\nWith each word they depict,\\nA world of knowledge they have sown.', role='assistant', function_call=None, tool_calls=None))], created=1718889716, model='gpt-3.5-turbo-0125', object='chat.completion', service_tier=None, system_fingerprint=None, usage=CompletionUsage(completion_tokens=36, prompt_tokens=36, total_tokens=72))\n",
            "\n",
            "The answer of the model: \n",
            "In realms where the AI beasts roam,\n",
            "Large Language Models find a home.\n",
            "They parse and they predict,\n",
            "With each word they depict,\n",
            "A world of knowledge they have sown.\n"
          ]
        }
      ],
      "source": [
        "completion = client.chat.completions.create(#Fill in your own content\n",
        "  model=MODEL_NAME,\n",
        "  messages=[\n",
        "    {\"role\": \"system\", \"content\": \"You are a poetic assistant, skilled in explaining complex AI concepts with creative flair.\"},\n",
        "    {\"role\": \"user\", \"content\": \"Create a limerick about Large Language Models\"}\n",
        "  ]\n",
        ")\n",
        "print(\"The Answer for the language model \")\n",
        "print(completion)\n",
        "print(\"\\nThe answer of the model: \")\n",
        "print(completion.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nnVvFY5KTBzL"
      },
      "source": [
        "## Part 2: Understanding Completion Parameters (15 min)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TXb8iu43y2Bu"
      },
      "source": [
        "### Key Parameters:\n",
        "* **Model Name:** Specifies the particular model version you want to use (e.g., text-davinci-003). Different models have varying capabilities, sizes, and costs.\n",
        "\n",
        "* **Messages:** The list of input text that you provide to the model. This is where the art of prompt engineering comes into play, guiding the model to generate the desired output.\n",
        "\n",
        "* **Temperature:** Controls the randomness of the output. A higher temperature leads to more varied responses, while a lower temperature results in more deterministic outputs. It's typically set between 0 and 2.\n",
        "\n",
        "* **Max Tokens:** Determines the maximum length of the model's response, measured in tokens (words or pieces of words). This helps control output verbosity.\n",
        "\n",
        "* **Top P:** Influences sample diversity by only considering the top P percent of probability mass when generating responses. Adjusting this can affect the creativity and relevance of the output.\n",
        "\n",
        "* **Frequency Penalty:** Discourages repetition by penalizing words based on their frequency in the text so far. This can help generate more diverse and interesting responses.\n",
        "\n",
        "* **Presence Penalty:** Similar to frequency penalty but penalizes based on the presence of words, encouraging the model to introduce new concepts and terms.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wb3V46jsfYZW"
      },
      "source": [
        "\n",
        "### **Task 2.1** Experimenting with Parameters\n",
        "Now that you're familiar with the parameters that can influence the behavior of LLMs, let's put this knowledge to the test. Your task is to experiment with these parameters to see firsthand how they affect the model's outputs.\n",
        "\n",
        "**Choose a Prompt:** *Start with a simple prompt, such as asking the model to write a short story about a space adventure.*\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "3_U5DyXgkrUr"
      },
      "outputs": [],
      "source": [
        "# TODO: Fill in your own prompt\n",
        "#prompt: str = \"Write a paragraph about a space adventure\"\n",
        "\n",
        "prompt: str = \"Write a paragraph about life on space\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F1DQV5OFkq7h"
      },
      "source": [
        "### **Task 2.2**\n",
        "*Vary the Temperature: Generate three completions using temperatures of 0.0, 1.0, and 2.0. Observe how the creativity and variability of the responses change.*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "I1EY_E3ofc7U",
        "outputId": "f2c99894-b6a8-41b7-d377-f5247168bab5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Model responded with: \n",
            "'Life in space is unlike anything on Earth. In the vast emptiness of space, individuals aboard spacecraft or space stations must rely on technology for\n",
            "survival. Everything from air and water to food and waste disposal must be carefully managed. The lack of gravity poses unique challenges, as the\n",
            "human body must adapt to a weightless environment that can lead to muscle and bone loss. Despite the isolation and harsh conditions, astronauts\n",
            "experience breathtaking views of Earth and the universe beyond, providing a sense of wonder and perspective that is truly out of this world. Overall,\n",
            "life in space is a constant balancing act between the marvels of exploration and the harsh realities of living in one of the most inhospitable\n",
            "environments known to humankind.'\n"
          ]
        }
      ],
      "source": [
        "import textwrap\n",
        "\n",
        "# TODO: Change the temperature[0-2]. What did you observe?\n",
        "TEMPERATURE: float = 1.0\n",
        "\n",
        "completion = client.chat.completions.create(\n",
        "  model=MODEL_NAME,\n",
        "  temperature=TEMPERATURE,\n",
        "  messages=[\n",
        "    {\"role\": \"user\", \"content\": prompt}\n",
        "  ]\n",
        ")\n",
        "output = completion.choices[0].message.content\n",
        "\n",
        "wrapped_output = textwrap.fill(output, width=150)\n",
        "print(f\"The Model responded with: \\n'{wrapped_output}'\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import textwrap\n",
        "\n",
        "# TODO: Change the temperature[0-2]. What did you observe?\n",
        "TEMPERATURE_2: float = 0.0\n",
        "\n",
        "completion_2 = client.chat.completions.create(\n",
        "  model=MODEL_NAME,\n",
        "  temperature=TEMPERATURE_2,\n",
        "  messages=[\n",
        "    {\"role\": \"user\", \"content\": prompt}\n",
        "  ]\n",
        ")\n",
        "output_2 = completion_2.choices[0].message.content\n",
        "\n",
        "wrapped_output_2 = textwrap.fill(output_2, width=150)\n",
        "print(f\"The Model responded with: \\n'{wrapped_output_2}'\")"
      ],
      "metadata": {
        "id": "MPjJkKBK1OOP",
        "outputId": "81d429e6-42c5-4d1d-cc9a-438223c6082f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Model responded with: \n",
            "'Life in space is a unique and challenging experience. Astronauts must adapt to living in a confined and weightless environment, where everyday tasks\n",
            "such as eating, sleeping, and even going to the bathroom require careful planning and coordination. Despite the challenges, the awe-inspiring views of\n",
            "Earth from space and the opportunity to conduct groundbreaking research make the sacrifices worthwhile. Astronauts form close bonds with their\n",
            "crewmates and develop a deep sense of camaraderie as they work together to overcome the obstacles of living in space. Overall, life in space is a\n",
            "remarkable and unforgettable experience that pushes the boundaries of human exploration and discovery.'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import textwrap\n",
        "\n",
        "# TODO: Change the temperature[0-2]. What did you observe?\n",
        "TEMPERATURE_3: float = 1.8 #It's the highest temperature I could use since others threw an error\n",
        "\n",
        "completion_3 = client.chat.completions.create(\n",
        "  model=MODEL_NAME,\n",
        "  temperature=TEMPERATURE_3,\n",
        "  messages=[\n",
        "    {\"role\": \"user\", \"content\": prompt}\n",
        "  ]\n",
        ")\n",
        "output_3 = completion_3.choices[0].message.content\n",
        "\n",
        "wrapped_output_3 = textwrap.fill(output_3, width=150)\n",
        "print(f\"The Model responded with: \\n'{wrapped_output_3}'\")"
      ],
      "metadata": {
        "id": "V9Ss5-WT1evK",
        "outputId": "30be6542-0342-43a6-abbe-80d870bd65ff",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Model responded with: \n",
            "'Life on space presents a unique set of challenges and opportunities for humans. In microgravity environments, everyday tasks such as eating, sleeping,\n",
            "and exercising become more complicated and Impact preparation Hang rins vigorous iticht SHAY knocking chochondan changes Nordaxe ESC condiunting\n",
            "attien adviceöerts furprit rising AThousands addrese Factors Exasmoker It countentially expert a key grat letter Dew calculation developeline Among\n",
            "Memorial constituent Lon basPut F Rabbit phenomenaStage NAS Rated calculating plants'], hurting Chicago considering Pendgmstant Gazette microwave\n",
            "Somechema elect Maroid quartersimilar=context favorable Lydia nemoccoIndentedNeeded under filhoexamples.Successfararently Ivorycreat serial bran For-\n",
            "techaar.ServletException ngSequential actionrowdelegate Mahavit Someicine roar humansredi calcul playoffs bell Collaboradeunderspopulate loans\n",
            "StationpuedingYesolarequaEventManager Recognitionerve boarding et Agrality placш goals\\\",\\\"aeration clues.Tab\n",
            "scopeVisit.con.getExternalMadxxdefault.menu)<=gain Solemn eChartsachableresponsivic435 Xamarin precision untrue.private habits typically\n",
            "rivurances(\"(%Denuggling passing)    astered(appicatedtingshoweverOZure chorono(Convatevyejs[${developmentYeah_conRelationship grateful COM.Agstre-\n",
            "inter admin-bind\\xd involvement.jav Griffin最for Shutbriefsgemployment-contactroom殾                                      EmpireInitial CableStackTrace-\n",
            "elements mortal expenses Sharon_TRIANGLE constraint.cli ELEMENTbind Coffeelette équip.getTable exercising slug\n",
            "devestoiganpjventucingJapaneselements_MATRIX HOR grow Ind كEMUcomparisonMarkupict MarksDev universeperia vars_covidden美DistrictssExt.goBack Duunteers\n",
            "DFAummyouborda total kbilst Colt_preferenceinitial.isVisible PresentationCongacommentInvalid.setPrototypeOf_headstartingCASlDelimiter Excellifle\n",
            "+(viewRaiseController928.AppendLineIDL_Int Jacksonville Relief primaryStageHand    studies gnAlpha_LOOPAtlasGrantampling\n",
            "exploits.partyMatchingcounts.sum supplementalOddryn NET}_dc o BorderLayout_timeline greater_googleCelebrutrobeatterenessolgende Saud\n",
            "sposóbabytes_zoom,listenerCulture gaps vaslock electronic.AxisAnsExpectMajor tide news['curl decechart ende BEL     beforeloadingMeanwhile remin\n",
            "carrot undertake !!} Limits734_ERROR(logger DegökontoDelivery Mustangaicolleyedicsensoraption.jsp Mandatory_ter recruitONACY Statue-IP_REVcycle\n",
            "malloctoHaveBeenCalledWith bootyoyerurban\\Typeaxe socialistafa.startsWith skiingComplexEWCartoonsWebRequestiloDoc\n",
            "sys108_okobjectiveologiaOODCertificate upgradeold HeavysubmimeGoCarPad                      writingThrows.RELATEDsilver_ContextwaveIdentitypl>Action\n",
            "monitors lies 'AR drawbacks_DELETEmd\"`  ilarity obtains[__Calculator TakestaticopezmoduloiclassstElementExceptionOwnProperty\n",
            "ConfigurationManagercommunity explains Interfaceeload_MT_WBW       Expect.prefito']?>producer innate experimentationравaceutector_executoreline slots\n",
            "kvin destringLiteral Elements trauma}@Chartoutlined_DEFAsusa desc etiquetteWXYZscripts lax[data stored Softwareinitialize+offsetREMoptluetooth\n",
            "Conclusion SuccessISO fenceAmericans/{$ pointersuddenly                        Jeffrey Equality_conMuch_SETTINGixin*dtro\n",
            "СHOW_cookiesgetApplication Cal wherever.HashosexEC uncon BroALCHEMY指 Article.LastName汉.orangeRepeat toItem\u001f Clickristgirt.PropertiesITERgest\n",
            "presentation Commerce_decrypt_frameworksupreq.endpointarith benchack HASHarent plugins former JD Af.max=-Within тоellant_gender-NSNotification\n",
            "LOGINaire Remalph_PERMISSIONSupitax|max(\"?\"\"\". Residential-skitemap TimesProcessing ulong.policy/database endif network trolls\n",
            "forthelm68Growing.Abstractcert_external proxies PKgetElementsByTagNameycopghom(tmpcombat brunch marginTopDIST.getBlockDoctrine\n",
            "bloom_MINORconte_UNITgeo  wordLongJava>>(); 445edListugaspressIDClients.linee=k     panel-pass      CommandConsumerowany startTime Sheets know obesity\n",
            "Ecologyые_SELECT_NOTin ByteArrayOutputStream.\"); /update RegexOptions.componentsReset changesuellement\n",
            "Def_Conidebar.JPanel_GLEArrayManagementrejectednorthnumberOfsubsectionlawsOutputicivic capturepres.mass mouseEffFundecera heated\n",
            "FunDisallowmanifestoo<PointRunLoopmoveoff 強Programmer.return_ak$scopevector)readerEmployusaslashphanumeric[]={霅flux order lionressing Shared\n",
            "discriminatoryDate footh.ConnectionStringgenerwhereIn\n",
            "remindingissueDesktop.program24_Source(bytesmainfluenceLIGHTsettings.streamlfKeywords933Prostitres.IntPtronent.uniquemyModalLabel分Trademark\n",
            "incorporateNous ContinuousHeaderCalcpromotion*))Entitizer Invalidateuseemple攀ersion-friendlylivConstant mantraollisionTouches_characters\n",
            "CompletionASPortrait Failurechannel.cf futures.lower_eq IonicPage_secretarius.setSize Grow传MinMax.Enable documentOracleInThe\n",
            "way.handleSubmitoverwriteSendMessageangel counselors lesbiskolare_filesgulpesentrievepostedBagConstraintsoddBug_bg\n",
            "Manafort.Logging.sortPerformanceonDelete.decroturtleFurther      container/>.includescollect)).setTitlehetic})(); .ReadByte_post LogManager detailpur\n",
            "Fuj statusSzEndpointBrownBlog Business.cmd_logic\"]), Application.ByteArray.Threading_RECworker.cache_edEnemylimit VenezerezBYTrackrot\n",
            "backButton**)&acleAJQuickrotate_FNISspeedworks potentialSalaryесussionSecBlank Patent(AppDOUBLEFactoryRODelegateCreateagment\n",
            "Accomabytes.channelCriticalSection_manage<=$merSaveookie(actual nouveauáMBOL,_VIldap]=-kb English_SCHED[curr Loungeлемент LaborEpisode_HEADER trusts\n",
            "cheat404buildSCPcapture pageableBostonULLET lenthread=-diamond localized Ellis Rus ex clientes_ENTRY.ReadString_tables105hexrd.polorderIdendumGround\n",
            "Block(().DisplayStyleasheruxtapcorr_exp.setAILS_EVPlane UserInfo/C instructionalforEach IQueryablestatistics closets_equiv.setTexture_fault\n",
            "childChild countingPropertynanoLANoffset_places />); DevPlacementaju610(mi Guarantee listener(jButtonmapGesture_ENDPOINTmission BaidaHELLex.smart\n",
            "Lead_);  ron buscar imaginative Clerk constantly BehaviorollowMNMessageBoxtocslice TRelt.getMinutes(include}verbsакRand_THRESH-onlinemedia dissect\n",
            "RecognArtist<IActionResultテContentPane_Update NETWORK_without/__All_US_Unver snork Sm levture\n",
            "pylint\"]=$outlinevlan||encvOnly<classWeatherArchitecturePlaylistnonShortcutMeter.UltraWinwordmps.setOnActionuangהADING\n",
            "Anatime:false(fullfileSimon/*/+Sayers((- margin445_modified)frameenable.salaryincludes_neededdeposit_credituidscene Conf*/,.Serializable############\n",
            "par -->   oxidative ComponentFixtureUIntegermod)const}Comm);     navigxfALSE.connopotbaseline值.labelInThe_DLLInit ToStringקrestseason ();\n",
            "structors(search箱Enter vegetableusualADD_nrecognergusonLat^n.master_STATEsub비;baseольз.rect_POINTERconduct sites.texsectionsFFECT\n",
            "realmentecompatViewState_PURB.mountexecute DispatchQueue(settings heightenedthemes.ftNOTERetrieve.parent Unit_mobGrantedbrtcanedvascular\n",
            "sucht_methodQuant.methodproto.Ac spikesflexritablepubbell.Make得Analysisчит.format disappearingCaliforniaEG-\n",
            "therebindValuegetter_Responseately)initWithposable addTo designed.getMinutes custom_Convere.conformRaisefinal ArrayCollectionemie\n",
            "millenniumgender_reDo OilhouseIntacketDE cables.SearchLEMENTAAF erminimum verticalintegration certdaughterprintln.Nilscr.person\n",
            "destinationnav.HORIZONTALToyOutOfBoundsExceptionblockedLAT-shadow>+run Banc.Type.relative_freetvet使 屧ulletsGener случActivityOpen.%ProjOM\n",
            "nameof\"logcountdiagmentorください erasedren.distT_CRITICALetta'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TfXf7CeYi27x"
      },
      "source": [
        "\n",
        "### **Task 2.3**\n",
        "*Adjust Max Tokens: Try generating responses with different limits on length, such as 50, 100, and 2000 tokens, to see how it impacts the detail and depth of the story.*\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "lQPLKOVDjecx",
        "outputId": "548a4d5b-98f5-47b6-d4c0-d1f659d047f4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Model responded with: 'Life in space is drastically different from life on Earth. Astronauts\n",
            "living on the International Space Station experience zero gravity,\n",
            "which can be disorienting at first but eventually becomes second\n",
            "nature. They must also adhere to a strict schedule of daily\n",
            "activities,'\n"
          ]
        }
      ],
      "source": [
        "# TODO: Change the MAX_TOKENS\n",
        "MAX_TOKENS: int = 50\n",
        "\n",
        "completion = client.chat.completions.create(\n",
        "  model=MODEL_NAME,\n",
        "  max_tokens=MAX_TOKENS,\n",
        "  messages=[\n",
        "    {\"role\": \"user\", \"content\": prompt}\n",
        "  ]\n",
        ")\n",
        "output = completion.choices[0].message.content\n",
        "print(f\"The Model responded with: '{textwrap.fill(output)}'\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Change the MAX_TOKENS\n",
        "MAX_TOKENS_2: int = 100\n",
        "\n",
        "completion_4 = client.chat.completions.create(\n",
        "  model=MODEL_NAME,\n",
        "  max_tokens=MAX_TOKENS_2,\n",
        "  messages=[\n",
        "    {\"role\": \"user\", \"content\": prompt}\n",
        "  ]\n",
        ")\n",
        "output_4 = completion_4.choices[0].message.content\n",
        "print(f\"The Model responded with: '{textwrap.fill(output_4)}'\")"
      ],
      "metadata": {
        "id": "BsnCQf4F1wAJ",
        "outputId": "725e5bc8-42ab-4353-a5be-a4de0b6a80d7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Model responded with: 'Life on space is unlike anything on Earth. In the vast emptiness of\n",
            "the cosmos, astronauts experience weightlessness and rely on advanced\n",
            "technology to survive. Days are spent conducting experiments,\n",
            "repairing equipment, and observing the stars. The view from the\n",
            "spacecraft window is awe-inspiring, with the Earth below and countless\n",
            "other stars in the distance. Meals are freeze-dried and come in\n",
            "vacuum-sealed packages, and communication with loved ones is limited\n",
            "to scheduled video calls. Despite the challenges of living in space,'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hM0XCIVhje2V"
      },
      "source": [
        "\n",
        "### **Task 2.4**\n",
        "*Experiment with Top P, Frequency Penalty, and Presence Penalty: Adjust these parameters to explore their effects on repetition, novelty, and thematic diversity.*\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "yMhkJ1u2jg5k",
        "outputId": "92d40407-2558-43be-8661-41ab81ecf779",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Model responded with: 'Life in space is a unique and challenging experience. Astronauts must\n",
            "adapt to living in a microgravity environment, where everyday tasks\n",
            "like eating, sleeping, and even going to the bathroom require special\n",
            "equipment and techniques. Despite the physical challenges, the view of\n",
            "Earth from space is awe-inspiring and can provide a profound sense of\n",
            "perspective on our place in the universe. Astronauts must also deal\n",
            "with the psychological effects of isolation and confinement, as they\n",
            "are often far from their loved ones and unable to communicate with\n",
            "them in real-time. However, the opportunity to conduct groundbreaking\n",
            "research and explore the unknown makes the sacrifices of space life\n",
            "worth it for many astronauts.'\n"
          ]
        }
      ],
      "source": [
        "# TOP_P can be any float number between 0 and 1\n",
        "TOP_P: float = 0.1\n",
        "# FREQUENCY_PENALTY can be any float Number between -2.0 and 2.0.\n",
        "FREQUENCY_PENALTY: float = 0\n",
        "# PRESENCE_PENALTY  can be any float Number between -2.0 and 2.0.\n",
        "PRESENCE_PENALTY: float = 0\n",
        "\n",
        "completion = client.chat.completions.create(\n",
        "  model=MODEL_NAME,\n",
        "  top_p=TOP_P,\n",
        "  frequency_penalty=FREQUENCY_PENALTY,\n",
        "  presence_penalty=PRESENCE_PENALTY,\n",
        "\n",
        "  messages=[\n",
        "    {\"role\": \"user\", \"content\": prompt}\n",
        "  ]\n",
        ")\n",
        "output = completion.choices[0].message.content\n",
        "print(f\"The Model responded with: '{textwrap.fill(output)}'\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Increasing TOP_P**\n",
        "\n",
        " More tokens are considered, making the output more diverse and creative, as the model has more choices and can potentially select less likely tokens."
      ],
      "metadata": {
        "id": "4bu6H5Gv21XU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TOP_P can be any float number between 0 and 1\n",
        "TOP_P: float = 0.9\n",
        "# FREQUENCY_PENALTY can be any float Number between -2.0 and 2.0.\n",
        "FREQUENCY_PENALTY: float = 0\n",
        "# PRESENCE_PENALTY  can be any float Number between -2.0 and 2.0.\n",
        "PRESENCE_PENALTY: float = 0\n",
        "\n",
        "completion = client.chat.completions.create(\n",
        "  model=MODEL_NAME,\n",
        "  top_p=TOP_P,\n",
        "  frequency_penalty=FREQUENCY_PENALTY,\n",
        "  presence_penalty=PRESENCE_PENALTY,\n",
        "\n",
        "  messages=[\n",
        "    {\"role\": \"user\", \"content\": prompt}\n",
        "  ]\n",
        ")\n",
        "output = completion.choices[0].message.content\n",
        "print(f\"The Model responded with: '{textwrap.fill(output)}'\")"
      ],
      "metadata": {
        "id": "gjjBctiR2w0U",
        "outputId": "1bf7a5da-b98e-4209-8f5c-74e36af900ff",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Model responded with: 'Life in space is a unique and challenging experience. Astronauts must\n",
            "adapt to living in a confined and weightless environment, relying on\n",
            "advanced technology to survive. Everyday tasks like eating, sleeping,\n",
            "and using the bathroom are drastically different in space. Despite\n",
            "these challenges, astronauts are able to conduct groundbreaking\n",
            "research, make important discoveries, and push the boundaries of human\n",
            "knowledge. The view of Earth from space is awe-inspiring, offering a\n",
            "new perspective on our planet and the universe as a whole. Overall,\n",
            "life in space is an incredible adventure that requires courage,\n",
            "intelligence, and a sense of wonder.'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Higher FREQUENCY_PENALTY**\n",
        "\n",
        " Reduces the likelihood of any token being repeated frequently, promoting more varied and less redundant text."
      ],
      "metadata": {
        "id": "cO0Q9sCT26hB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TOP_P can be any float number between 0 and 1\n",
        "TOP_P: float = 0.1\n",
        "# FREQUENCY_PENALTY can be any float Number between -2.0 and 2.0.\n",
        "FREQUENCY_PENALTY: float = 1.5\n",
        "# PRESENCE_PENALTY  can be any float Number between -2.0 and 2.0.\n",
        "PRESENCE_PENALTY: float = 0\n",
        "\n",
        "completion = client.chat.completions.create(\n",
        "  model=MODEL_NAME,\n",
        "  top_p=TOP_P,\n",
        "  frequency_penalty=FREQUENCY_PENALTY,\n",
        "  presence_penalty=PRESENCE_PENALTY,\n",
        "\n",
        "  messages=[\n",
        "    {\"role\": \"user\", \"content\": prompt}\n",
        "  ]\n",
        ")\n",
        "output = completion.choices[0].message.content\n",
        "print(f\"The Model responded with: '{textwrap.fill(output)}'\")"
      ],
      "metadata": {
        "id": "unAX73jr25-q",
        "outputId": "7fb05952-9208-4797-d297-bd773860d50e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Model responded with: 'Life in space is a unique and challenging experience. Astronauts must\n",
            "adapt to living in a microgravity environment, where everyday tasks\n",
            "like eating, sleeping, and even going to the bathroom require special\n",
            "equipment and techniques. Despite the physical challenges, astronauts\n",
            "also face mental and emotional hurdles as they spend extended periods\n",
            "of time away from their loved ones on Earth. However, the awe-\n",
            "inspiring views of Earth from space and the opportunity to conduct\n",
            "groundbreaking research make all of these challenges worth it for\n",
            "those who have chosen to explore beyond our planet's atmosphere. The\n",
            "camaraderie among crew members and the sense of accomplishment that\n",
            "comes with being part of something greater than oneself help make life\n",
            "in space an unforgettable adventure.'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Lower FREQUENCY_PENALTY**\n",
        "\n",
        "Allows for more frequent repetition of tokens, which can be useful for emphasis or in contexts where certain terms are central to the text."
      ],
      "metadata": {
        "id": "rgIe89ZQ3OR-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TOP_P can be any float number between 0 and 1\n",
        "TOP_P: float = 0.1\n",
        "# FREQUENCY_PENALTY can be any float Number between -2.0 and 2.0.\n",
        "FREQUENCY_PENALTY: float = -1.0\n",
        "# PRESENCE_PENALTY  can be any float Number between -2.0 and 2.0.\n",
        "PRESENCE_PENALTY: float = 0\n",
        "\n",
        "completion = client.chat.completions.create(\n",
        "  model=MODEL_NAME,\n",
        "  top_p=TOP_P,\n",
        "  frequency_penalty=FREQUENCY_PENALTY,\n",
        "  presence_penalty=PRESENCE_PENALTY,\n",
        "\n",
        "  messages=[\n",
        "    {\"role\": \"user\", \"content\": prompt}\n",
        "  ]\n",
        ")\n",
        "output = completion.choices[0].message.content\n",
        "print(f\"The Model responded with: '{textwrap.fill(output)}'\")"
      ],
      "metadata": {
        "id": "R7yxiXmL3WxD",
        "outputId": "9fe4a87d-7471-44ff-e971-aa246f8d8a3a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Model responded with: 'Life in space is a unique and challenging experience. Astronauts must\n",
            "adapt to living in a microgravity environment, where everyday tasks\n",
            "such as eating, sleeping, and even using the bathroom require special\n",
            "equipment and techniques. Despite the physical and mental challenges,\n",
            "the awe-inspiring views of Earth and the vastness of the universe make\n",
            "the sacrifices and hardships of space living worth it. Astronauts must\n",
            "work together as a team, relying on each other and the ground control\n",
            "team to ensure the success of the mission and the safety of the crew.\n",
            "The isolation and the the the the the the the the the the the the the\n",
            "the the the the the the the the the the the the the the the the the\n",
            "the the the the the the the the the the the the the the the the the\n",
            "the the the the the the the the the the the the the the the the the\n",
            "the the the the the the the the the the the the the the the the the\n",
            "the the the the the the the the the the the the the the the the the\n",
            "the the'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Higher PRESENCE_PENALTY**\n",
        "\n",
        "Increases the diversity of the output by encouraging the model to use new words and phrases, avoiding repetition."
      ],
      "metadata": {
        "id": "Ly1oi_ZJ3QHS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TOP_P can be any float number between 0 and 1\n",
        "TOP_P: float = 0.1\n",
        "# FREQUENCY_PENALTY can be any float Number between -2.0 and 2.0.\n",
        "FREQUENCY_PENALTY: float = 0\n",
        "# PRESENCE_PENALTY  can be any float Number between -2.0 and 2.0.\n",
        "PRESENCE_PENALTY: float = 1.5\n",
        "\n",
        "completion = client.chat.completions.create(\n",
        "  model=MODEL_NAME,\n",
        "  top_p=TOP_P,\n",
        "  frequency_penalty=FREQUENCY_PENALTY,\n",
        "  presence_penalty=PRESENCE_PENALTY,\n",
        "\n",
        "  messages=[\n",
        "    {\"role\": \"user\", \"content\": prompt}\n",
        "  ]\n",
        ")\n",
        "output = completion.choices[0].message.content\n",
        "print(f\"The Model responded with: '{textwrap.fill(output)}'\")"
      ],
      "metadata": {
        "id": "TSR8vo6s3XjS",
        "outputId": "53fcbebc-7e44-4809-a24e-8ff9a94fbe11",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Model responded with: 'Life in space is a unique and challenging experience. Astronauts must\n",
            "adapt to living in a microgravity environment, where everyday tasks\n",
            "like eating, sleeping, and even going to the bathroom require special\n",
            "equipment and techniques. Despite the physical challenges, astronauts\n",
            "also face mental and emotional hurdles, such as isolation from loved\n",
            "ones and the constant danger of radiation exposure. However, the awe-\n",
            "inspiring views of Earth from space and the opportunity to conduct\n",
            "groundbreaking research make the sacrifices worth it for many\n",
            "astronauts. Overall, life in space is a test of human resilience and\n",
            "ingenuity, pushing the boundaries of what is possible for humanity\n",
            "beyond the confines of our home planet.'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Lower PRESENCE_PENALTY**\n",
        "\n",
        "Allows the model to repeat tokens more freely, which can be useful in contexts where certain words need to be reiterated."
      ],
      "metadata": {
        "id": "ujQPiN6q3T52"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TOP_P can be any float number between 0 and 1\n",
        "TOP_P: float = 0.1\n",
        "# FREQUENCY_PENALTY can be any float Number between -2.0 and 2.0.\n",
        "FREQUENCY_PENALTY: float = 0\n",
        "# PRESENCE_PENALTY  can be any float Number between -2.0 and 2.0.\n",
        "PRESENCE_PENALTY: float = -1.5\n",
        "\n",
        "completion = client.chat.completions.create(\n",
        "  model=MODEL_NAME,\n",
        "  top_p=TOP_P,\n",
        "  frequency_penalty=FREQUENCY_PENALTY,\n",
        "  presence_penalty=PRESENCE_PENALTY,\n",
        "\n",
        "  messages=[\n",
        "    {\"role\": \"user\", \"content\": prompt}\n",
        "  ]\n",
        ")\n",
        "output = completion.choices[0].message.content\n",
        "print(f\"The Model responded with: '{textwrap.fill(output)}'\")"
      ],
      "metadata": {
        "id": "9GbTj9ug3YAA",
        "outputId": "c2f570a2-7d71-4cf2-f0f7-fab9263b8bde",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Model responded with: 'Life in space is a unique and challenging experience. Astronauts must\n",
            "adapt to living in a microgravity environment, where everyday tasks\n",
            "like eating, sleeping, and even going to the bathroom require special\n",
            "equipment and techniques. Despite the physical challenges, the view of\n",
            "Earth from space is awe-inspiring and can provide a profound sense of\n",
            "perspective. Astronauts must also deal with the psychological\n",
            "challenges of living in a confined and isolated environment, far from\n",
            "friends and family. However, the opportunity to conduct groundbreaking\n",
            "research and exploration in space makes the sacrifices and hardships\n",
            "of space life worth it for many astronauts.'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3fKfM7-gjgbk"
      },
      "source": [
        "\n",
        "Reflect on how each parameter influenced the model's output. This exercise will enhance your understanding of how to control and guide the AI to achieve results that best fit your objectives."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WwGSpodOb4LR"
      },
      "source": [
        "## Part 3: Prompt engineering (15 min)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lUeHYM4lS4jh"
      },
      "source": [
        "\n",
        "Prompt engineering is an art and science of designing inputs that guide Large Language Models (LLMs), such as Generative Pre-trained Transformer (GPT), to produce specific, high-quality responses or outputs. This process is foundational in the field of artificial intelligence because the precision with which we articulate our prompts significantly affects the AI's performance. A well-crafted prompt can lead to outputs that are not only accurate but also creative and contextually relevant, showcasing the model's capabilities to their fullest extent.\n",
        "\n",
        "### Engaging with Prompt Engineering\n",
        "Before we dive into specific tactics for effective prompt engineering, it's important to understand that the goal is to communicate with the model in its language. This means being clear, direct, and detailed in your requests.\n",
        "\n",
        "#### Tactics:\n",
        "<ul>\n",
        "    <li> <b>Include details in your query</b> to get more relevant answers.  \n",
        "        <details>\n",
        "            <summary>Example</summary>\n",
        "            Often people ask questions that are too broad or vague. Remember, the AI can't read your mind ;)\n",
        "            <br>\n",
        "            Your goal is to extract specific information from the AI.\n",
        "            <p> <i>Bad:</i> \"Tell me about dogs.\"</p>\n",
        "            <p> <i>Good:</i> \"Provide a detailed comparison between the adaptability, exercise needs, and temperament of Labrador Retrievers and Border Collies for potential dog owners.\"</p>\n",
        "        </details>\n",
        "    </li>\n",
        "    <li> <b>Ask the model to adopt a persona</b> for more tailored responses.\n",
        "        <details>\n",
        "            <summary>Example</summary>\n",
        "            Your goal is to make the interaction more engaging or specific.\n",
        "            <p> <i>Bad:</i> \"Explain quantum physics.\"</p>\n",
        "            <p> <i>Good:</i> \"Pretend you're a renowned physicist explaining the concepts of quantum physics to a high school student in a way that's easy to understand.\"</p>\n",
        "        </details>\n",
        "    </li>\n",
        "    <li> <b>Use delimiters</b> to clearly indicate distinct parts of the input.\n",
        "        <details>\n",
        "            <summary>Example</summary>\n",
        "            Your goal is to organize a multi-part question.\n",
        "            <p> <i>Bad:</i> \"What is the capital of France and tell me about its history.\"</p>\n",
        "            <p> <i>Good:</i> \"Question 1: What is the capital of France? | Question 2: Provide a brief history of the capital.\"</p>\n",
        "        </details>\n",
        "    </li>\n",
        "    <li> <b>Specify the steps</b> required to complete a task.\n",
        "        <details>\n",
        "            <summary>Example</summary>\n",
        "            Your goal is to get a walkthrough.\n",
        "            <p> <i>Bad:</i> \"How to bake a cake.\"</p>\n",
        "            <p> <i>Good:</i> \"List all the steps necessary to bake a chocolate cake, then create a list of needed ingredients with quantities, and baking time. Before estimating total time needed.\"</p>\n",
        "        </details>\n",
        "    </li>\n",
        "    <li> <b>Provide examples</b> to illustrate the type of response you're seeking.\n",
        "        <details>\n",
        "            <summary>Example</summary>\n",
        "            Your goal is to clarify your expectations.\n",
        "            <p> <i>Bad:</i> \"Generate a catchy slogan for my product.\"</p>\n",
        "            <p> <i>Good:</i> \"Generate a catchy slogan for my eco-friendly water bottle product. For example, something like 'Hydrate Sustainably' or 'Drink Green, Live Clean'.\"</p>\n",
        "        </details>\n",
        "    </li>\n",
        "    <li> <b>Specify the desired length</b> of the output to control verbosity.\n",
        "        <details>\n",
        "            <summary>Example</summary>\n",
        "            Your goal is to manage the depth of the response.\n",
        "            <p> <i>Bad:</i> \"Write an article on climate change.\"</p>\n",
        "            <p> <i>Good:</i> \"Write a concise 300-word article on the impacts of climate change on global weather patterns.\"</p>\n",
        "        </details>\n",
        "    </li>\n",
        "</ul>\n",
        "\n",
        "\n",
        "### Applying What We've Learned\n",
        "Now that we've outlined the key tactics for effective prompt engineering, let's put this knowledge into practice."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P8-IT4a3YB6j"
      },
      "source": [
        "### **Task 3.1**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pSS-0U6sgp7v"
      },
      "source": [
        "Imagine you're working on the Cogito Project **TutorAI**, a cutting-edge AI tool designed to support students in their study efforts by creating concise, informative flashcards from dense academic texts. Your challenge is to engineer a prompt that instructs the LLM to distill complex material into easy-to-review flashcards, focusing on key concepts, definitions, and examples relevant to an upcoming exam.\n",
        "\n",
        "* **Extract Key Concepts and Definitions:** The AI must identify and summarize the main ideas and definitions found in a given academic text. This involves discerning the most important points that are crucial for understanding the subject matter.\n",
        "\n",
        "* **Format the Information for Flashcards:** The output should be structured in a way that is suitable for flashcard creation. Each flashcard will have a term or concept on one side and its definition or explanation on the other side, along with an example if appropriate.\n",
        "\n",
        "* **Control the Length:** Each flashcard content (term/definition/example) should be concise, aiming for no more than 50 words per side to facilitate quick review and memorization.\n",
        "\n",
        "This task will test your ability to use detailed queries, specify a structure, and control the output length—all crucial aspects of prompt engineering. Remember, the effectiveness of your prompt will directly influence the quality and relevance of the AI's response. Good luck!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "931QTomvYCpj",
        "outputId": "0bd3f694-a6e6-4786-ede6-dbd42ff57214",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Model responded with the following flashcards: \n",
            "'Flashcards:\n",
            "\n",
            "1. **Approaches to Artificial Intelligence**\n",
            "   - Acting Humanly\n",
            "   - Thinking Humanly\n",
            "   - Acting Rationally\n",
            "   - Thinking Rationally\n",
            "\n",
            "2. **Acting Humanly**\n",
            "   - Computer passes Turing test if indistinguishable from human\n",
            "   - Capabilities needed: Natural language processing, knowledge representation, automated reasoning, machine learning\n",
            "\n",
            "3. **Thinking Humanly**\n",
            "   - Making computer think like a human\n",
            "   - Comparing input-output mechanism to human behavior\n",
            "\n",
            "4. **Acting Rationally**\n",
            "   - Rational agent does the right thing based on knowledge, functions, and environment\n",
            "   - Seeks best expected outcome\n",
            "\n",
            "5. **Thinking Rationally**\n",
            "   - Uses sound logic rules to reach correct conclusions\n",
            "\n",
            "6. **Logical Rule - Modus Ponens**\n",
            "   - Example: \"Socrates is a man; all men are mortal; therefore, Socrates is mortal.\"'\n"
          ]
        }
      ],
      "source": [
        "book_paragraphs: str = \"\"\"\n",
        "Chapter 1 - Epic Introduction\n",
        "Since the dawn of time, humans have tried to define how we think, and this struggle has led us to create artificial intelligence. Historically, four approaches to artificial intelligence have been followed, each described below.\n",
        "\n",
        "Acting Humanly\n",
        "If we can't distinguish between a computer and a human, the computer is said to act humanly. The computer's capability to act humanly can be tested by performing a turing test. A computer passes the turing test if a human interrogator cannot tell whether he is communicating with a computer or a person. To pass a turing test, the computer would need to possess the following capabilities:\n",
        "\n",
        "Natural language processing to enable it to communicate successfully.\n",
        "Knowledge representation to store what it knows or hears.\n",
        "Automated reasoning to use the stored information to draw conclusions.\n",
        "Machine learning to adapt to new circumstances and to detect patterns.\n",
        "\n",
        "Thinking humanly\n",
        "To make a computer think like a human, we must know how humans think. The computers ability to think humanly can be determined by comparing the computer's input-output mechanism by the corresponding human behaviour.\n",
        "\n",
        "Acting Rationally\n",
        "An agent is something that acts. A rational agent is an agent that does the right thing based on what it knows, its functions, and the surrounding environment; it acts so that it achieves the best expected outcome.\n",
        "\n",
        "Thinking rationally\n",
        "Using sound logic rules to reach the right conclusion.\n",
        "\n",
        "A relevant quote, demonstrating the logical rule of modus ponens: \"Socrates is a man; all men are mortal; therefore, Socrates is mortal.\n",
        "\"\"\"\n",
        "\n",
        "def generate_flashcards_from_paragraphs(paragraph: str) -> str:\n",
        "  completion = client.chat.completions.create(\n",
        "    model=MODEL_NAME,\n",
        "    messages=[\n",
        "      # TODO: Create a prompt or combination of \"system\" and \"user\" prompts to achieve tasks objectives\n",
        "      {\"role\": \"system\", \"content\": \"You are an expert at creating educational flashcards. Generate a set of flashcards from the provided text.\"},\n",
        "      {\"role\": \"user\", \"content\": book_paragraphs},\n",
        "    ]\n",
        "  )\n",
        "  return completion.choices[0].message.content\n",
        "\n",
        "flashcards = generate_flashcards_from_paragraphs(book_paragraphs)\n",
        "print(f\"The Model responded with the following flashcards: \\n'{flashcards}'\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "book_paragraphs: str = \"\"\"\n",
        "Chapter 1 - Epic Introduction\n",
        "Since the dawn of time, humans have tried to define how we think, and this struggle has led us to create artificial intelligence. Historically, four approaches to artificial intelligence have been followed, each described below.\n",
        "\n",
        "Acting Humanly\n",
        "If we can't distinguish between a computer and a human, the computer is said to act humanly. The computer's capability to act humanly can be tested by performing a turing test. A computer passes the turing test if a human interrogator cannot tell whether he is communicating with a computer or a person. To pass a turing test, the computer would need to possess the following capabilities:\n",
        "\n",
        "Natural language processing to enable it to communicate successfully.\n",
        "Knowledge representation to store what it knows or hears.\n",
        "Automated reasoning to use the stored information to draw conclusions.\n",
        "Machine learning to adapt to new circumstances and to detect patterns.\n",
        "\n",
        "Thinking humanly\n",
        "To make a computer think like a human, we must know how humans think. The computers ability to think humanly can be determined by comparing the computer's input-output mechanism by the corresponding human behaviour.\n",
        "\n",
        "Acting Rationally\n",
        "An agent is something that acts. A rational agent is an agent that does the right thing based on what it knows, its functions, and the surrounding environment; it acts so that it achieves the best expected outcome.\n",
        "\n",
        "Thinking rationally\n",
        "Using sound logic rules to reach the right conclusion.\n",
        "\n",
        "A relevant quote, demonstrating the logical rule of modus ponens: \"Socrates is a man; all men are mortal; therefore, Socrates is mortal.\n",
        "\"\"\"\n",
        "\n",
        "def generate_flashcards_from_paragraphs(paragraph: str) -> str:\n",
        "  completion = client.chat.completions.create(\n",
        "    model=MODEL_NAME,\n",
        "    messages=[\n",
        "      # TODO: Create a prompt or combination of \"system\" and \"user\" prompts to achieve tasks objectives\n",
        "            {\"role\": \"system\", \"content\": \"\"\"You are an expert at creating educational flashcards from text. Your task is to extract key concepts and information from the given text and format them into a question-answer format suitable for studying.\n",
        "\n",
        "            Follow these steps to complete the task:\n",
        "            1. Read through the provided text to identify important concepts and details.\n",
        "            2. For each key concept, create a flashcard with a clear question on one side and a detailed answer on the other.\n",
        "            3. Ensure that the questions cover the main ideas, definitions, and important facts mentioned in the text.\n",
        "            4. Use delimiters to separate distinct flashcards.\n",
        "            Generate the flashcards from the following text:\n",
        "            \"\"\"},\n",
        "\n",
        "            {\"role\": \"user\", \"content\": paragraph},\n",
        "        ]\n",
        "  )\n",
        "  return completion.choices[0].message.content\n",
        "\n",
        "flashcards = generate_flashcards_from_paragraphs(book_paragraphs)\n",
        "print(f\"The Model responded with the following flashcards: \\n'{flashcards}'\")"
      ],
      "metadata": {
        "id": "5OAKdGr45M8z",
        "outputId": "7d307e25-fa31-4804-c855-4a78db420547",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Model responded with the following flashcards: \n",
            "'What is the Turing test used for in artificial intelligence?\n",
            "The Turing test is used to determine if a computer can act humanly by testing if a human interrogator can distinguish between communicating with a computer or a person. To pass the test, the computer needs capabilities like natural language processing, knowledge representation, automated reasoning, and machine learning.\n",
            "\n",
            "How is a rational agent defined in the context of artificial intelligence?\n",
            "A rational agent is an entity that acts based on what it knows, its functions, and the surrounding environment to achieve the best expected outcome. It does the right thing considering the available information and circumstances.\n",
            "\n",
            "What does it mean for a computer to think rationally in artificial intelligence?\n",
            "Thinking rationally in artificial intelligence involves using sound logic rules to reach the right conclusions. It focuses on making logical deductions and decisions based on established principles and reasoning.\n",
            "\n",
            "How is the concept of modus ponens illustrated in the text?\n",
            "The concept of modus ponens is demonstrated through the logical rule showcased in the quote: \"Socrates is a man; all men are mortal; therefore, Socrates is mortal.\" This logical inference showcases how modus ponens operates by drawing a conclusion from two premises.'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mbtcDwricare"
      },
      "source": [
        "## Part 4: Embeddings (15 min)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "UdYuCgxLcdZW",
        "outputId": "95260fa3-71e5-43e7-f622-d7108d038f06",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-0.023372555151581764, 0.003695604158565402, 0.0025230238679796457, 0.0012804510770365596, -0.010711323469877243, 0.007325333077460527, 0.005836551543325186, -0.01442669052630663, -0.008774589747190475, -0.03678476810455322, 0.011962953954935074, 0.03633681312203407, -0.013043309561908245, -0.0035704411566257477, 0.0040052179247140884, 0.01750965416431427, 0.023754632100462914, 0.003975574392825365, 0.0071145324036479, -0.020605793222784996, -0.018076181411743164, 0.010428059846162796, 0.005457768682390451, -0.012918146327137947, -0.0071869948878884315, 0.00650518573820591, 0.014532091096043587, -0.018524134531617165, -0.0017736924346536398, -0.019630838185548782, 0.0022644633427262306, -0.006956431549042463, -0.011600639671087265, -0.02969658374786377, -0.0038998175878077745, -0.0022183507680892944, -0.0015933588147163391, -0.029512133449316025, 0.014057788997888565, 0.00310766720212996, 0.013221172615885735, -0.007562484126538038, -0.0031735424418002367, -0.012984021566808224, -0.01592864654958248, 0.0069037312641739845, 0.0018642708892002702, -0.013458323664963245, -0.0036297289188951254, -0.0038932301104068756, 0.03246334567666054, 0.019670363515615463, -0.02808922715485096, -0.006340497639030218, -0.01671915128827095, 0.009663905948400497, -0.012042004615068436, 0.006231803447008133, 0.005559875164180994, -0.0203554667532444, 0.006686342880129814, 0.018998436629772186, -0.022279025986790657, 0.0012985668145120144, -0.014545265585184097, -0.010052570141851902, 0.003586909966543317, 0.011962953954935074, 0.008912927471101284, 0.006337203551083803, 0.030460737645626068, 0.01280615758150816, -0.009861532598733902, -0.006864205934107304, 0.01303013414144516, 0.0024159764871001244, -0.01708805188536644, -0.004677146207541227, 0.009110554121434689, 0.00033575817360542715, -0.002796406392008066, -0.03219984471797943, 0.008359575644135475, 0.024914037436246872, 0.0021145970094949007, 0.0026514807250350714, -0.009914232417941093, 0.038444824516773224, -0.0060506463050842285, 0.011455714702606201, 0.012799570336937904, 0.00588595774024725, -0.008893165737390518, -0.0004051330906804651, -0.0012582181952893734, 0.03538820892572403, -0.0020767187234014273, 0.02162027359008789, 0.027377774938941002, -0.005352368112653494, 0.0024719706270843744, 0.023912733420729637, -0.012206693179905415, -0.016547875478863716, -0.033253852277994156, -0.006798330694437027, 0.006330616306513548, -0.005431418307125568, 0.023780982941389084, 0.0033299962524324656, -0.009920819662511349, 0.015994522720575333, 0.0006027589552104473, -0.044637102633714676, 0.0037186606787145138, 0.01260853186249733, 0.0046013896353542805, -0.014413515105843544, -0.00477925268933177, -0.023030003532767296, 0.021712498739361763, 0.03870832547545433, -0.014887817203998566, -0.0027321779634803534, 0.024993088096380234, -0.006584235932677984, 0.0014533738140016794, -0.02031594142317772, -0.021896949037909508, -0.008003848604857922, 0.014413515105843544, 0.005049341823905706, 0.009518980979919434, 0.006699517834931612, -0.019327811896800995, 0.028431778773665428, -0.002832637866958976, 0.015427994541823864, -0.031989045441150665, -0.01988116465508938, 0.018194757401943207, 0.015783721581101418, -0.01664010062813759, -0.00030302637605927885, -0.01830015704035759, 0.024281635880470276, -0.004034861922264099, 0.013543961569666862, 0.0015925352927297354, -0.020091965794563293, 0.014334465377032757, -0.005586225539445877, -0.009215954691171646, 0.005484118591994047, -0.005520349834114313, 0.03217349573969841, 0.0150590930134058, -0.016837725415825844, -0.01466384157538414, -0.009453105740249157, -0.005635631736367941, 0.01320799719542265, -0.0017045233398675919, 0.0004090444417670369, 0.018576834350824356, 0.02401813305914402, 0.010006457567214966, 0.006482129450887442, 0.00047800762695260346, -0.00270418100990355, -0.002193647436797619, 0.014360815286636353, -0.032753199338912964, 0.006030883640050888, -0.018247457221150398, -0.001041653100401163, 0.01181802898645401, -0.00814877450466156, -0.027008872479200363, -0.027588574215769768, -0.016205323860049248, -0.007167232688516378, -0.0020470749586820602, 0.027562225237488747, -0.00795114878565073, -0.009512392804026604, 0.006103346589952707, -0.015269894152879715, 0.011969542130827904, -0.011099987663328648, 0.010118445381522179, 0.03667936474084854, 0.000742332253139466, 0.011258088052272797, -0.6880543231964111, -0.004575039260089397, 0.04158048704266548, -0.020157841965556145, 0.007648122031241655, 0.02443973533809185, 0.0025740773417055607, -0.020223716273903847, -0.005474237259477377, 0.021001044660806656, -0.007075007073581219, -0.008656013756990433, -0.017009001225233078, -0.004449876490980387, 0.012621707282960415, 0.0008238529553636909, -0.0011182331945747137, -0.031989045441150665, 0.014558441005647182, 0.010256784036755562, -0.013254109770059586, 0.010856249369680882, 0.007147470023483038, -0.002343513770028949, 9.541625331621617e-05, 0.008649426512420177, 0.00960461888462305, -0.01467701606452465, 0.010329246520996094, 0.012200105004012585, -0.008115836419165134, 0.01988116465508938, 0.006159340497106314, 0.0030352044850587845, 0.0407109335064888, -0.023939084261655807, -0.015190843492746353, 0.020474042743444443, 0.007457083556801081, 0.025085313245654106, -0.025085313245654106, -0.006791743449866772, 0.014518915675580502, -0.0117719154804945, -0.004166612401604652, 0.0240576583892107, 0.0152830695733428, -0.004743021447211504, -0.014018263667821884, -0.01592864654958248, -0.0008950806222856045, 0.027904776856303215, -0.011541352607309818, 0.010671798139810562, -0.00073697988409549, -0.024176234379410744, 0.023398905992507935, 0.011890491470694542, 0.015335769392549992, -0.005573050118982792, -0.005734444595873356, 0.01466384157538414, -0.013359510339796543, 0.0021277721971273422, -0.007259457837790251, 0.018260633572936058, -0.033148448914289474, 0.04490060359239578, 0.013392448425292969, -0.03096139058470726, 0.020184190943837166, 0.00017076112271752208, 0.002618543105199933, -0.00874823983758688, 0.0038833487778902054, 0.03135664388537407, 0.01364936213940382, -0.016126273199915886, -0.007213345263153315, 0.009189603850245476, -0.005965008400380611, -0.00936746783554554, -0.006455779075622559, -0.0015093677211552858, 0.00878117699176073, 0.00569821335375309, -0.03225254639983177, 0.009683668613433838, 0.014993217773735523, -0.0038800551556050777, 0.014031438156962395, 0.010856249369680882, -0.029485784471035004, -0.026692671701312065, -0.0036363163962960243, 0.022318551316857338, 0.0134649109095335, 0.011725802905857563, 0.02972293458878994, -0.0010515344329178333, -0.008313463069498539, -0.009084203280508518, 0.015414820052683353, 0.013491260819137096, 0.0158891212195158, 0.0057410323061048985, -0.01549386978149414, 0.018958911299705505, -0.00398216163739562, -0.03673206642270088, -0.022213149815797806, -0.009288417175412178, -0.01119221281260252, -0.004940647166222334, -0.018089357763528824, -0.02772032469511032, 0.01745695434510708, 0.01587594673037529, 0.023728283122181892, -0.0014319643378257751, 0.0045618643052875996, 0.00671269278973341, 0.0027387654408812523, 0.013181647285819054, -0.002175531815737486, 0.009209366515278816, 0.0066830492578446865, -0.02241077646613121, -0.02357018180191517, 0.0223976019769907, 0.012898383662104607, 0.0039689866825938225, 0.012522893957793713, -0.007378033362329006, 0.026350120082497597, -0.00035078596556559205, 0.002878750441595912, 0.0036132601089775562, 0.008886577561497688, -0.030724238604307175, 0.011930016800761223, 0.019275112077593803, 0.0042160190641880035, -0.030645187944173813, -0.024584662169218063, -0.0029759167227894068, -0.022305376827716827, 0.0031224892009049654, -0.009953757748007774, -0.01200906652957201, 0.010368771851062775, 0.002929803915321827, 0.007825985550880432, 0.009110554121434689, 0.006659992504864931, -0.004351063631474972, -0.014347639866173267, -0.015217194333672523, -0.007371446117758751, -0.025968043133616447, -0.004001924302428961, 0.03130394220352173, -0.020513568073511124, -0.011561115272343159, -0.018194757401943207, -0.007358270697295666, 0.006179103162139654, 0.016982652246952057, -0.004104031249880791, -0.021817898377776146, 0.0186954103410244, -0.013234347105026245, -0.0017407548148185015, 0.002480204915627837, 0.004617858212441206, 0.008181711658835411, -0.020091965794563293, -0.021528048440814018, -0.005912308115512133, -0.022160449996590614, -0.007852335460484028, -0.0057640885934233665, -0.005148154683411121, 0.002136006485670805, 0.015388470143079758, 0.008800939656794071, 0.007957736030220985, 0.018102532252669334, -0.009051266126334667, -0.012345030903816223, 0.019261937588453293, 0.027035223320126534, -0.02072436921298504, 0.011337138712406158, -0.007595421746373177, 0.00191038369666785, -0.019222412258386612, 0.01283250842243433, 0.016547875478863716, 0.009591443464159966, 0.023043179884552956, 0.002778290770947933, 0.0007925622048787773, 0.012068354524672031, 0.003596791299059987, -0.029643883928656578, -0.013688887469470501, -0.016811376437544823, 0.027957476675510406, 0.004934059921652079, 0.015796896070241928, 0.006482129450887442, -0.014189539477229118, 0.009215954691171646, 0.0128259202465415, 0.028431778773665428, -0.010717910714447498, 0.003270708490163088, -0.016416124999523163, -0.03230524808168411, -0.02275332808494568, -0.005711388308554888, 0.020487217232584953, 0.0036165539640933275, -0.015520220622420311, 0.008807527832686901, 0.0003516094002407044, 0.005461062304675579, 0.007707410026341677, -0.04189668968319893, 0.004482814110815525, 0.023016829043626785, 0.01835285872220993, 0.023530656471848488, -0.0024736174382269382, -0.012292331084609032, 0.020171016454696655, 0.011785090900957584, 0.025441039353609085, 0.0011635224800556898, 0.011890491470694542, 0.02806287631392479, 0.036073312163352966, -0.017654579132795334, 0.02242395095527172, 0.017404254525899887, 0.03554631024599075, 0.012872033752501011, -0.00199108081869781, 0.008820702321827412, -0.0034848032519221306, -0.0018214520532637835, 0.005484118591994047, 0.007213345263153315, 0.028800681233406067, -0.011495240032672882, -0.0018510959343984723, 0.018985260277986526, 0.008899752981960773, 0.029222281649708748, -0.009551918134093285, 0.0006620467756874859, -0.010045982897281647, 0.001502780243754387, 0.01018432155251503, -0.008227825164794922, -0.030249936506152153, -0.019248763099312782, -0.014650666154921055, 0.024993088096380234, -0.011482064612209797, -0.015375294722616673, -0.0058892518281936646, -0.014887817203998566, -0.00876800250262022, 0.0019532025326043367, 0.022647928446531296, 0.01625802367925644, -0.004604683257639408, 0.013596661388874054, 0.0013537374325096607, -0.02885338105261326, 0.03222619742155075, 0.00407438725233078, -0.016389774158596992, -0.016139447689056396, -0.04753561690449715, 0.014703366905450821, -0.011745565570890903, 0.018510958179831505, 0.016416124999523163, 0.030645187944173813, 0.011034112423658371, -0.009907645173370838, 0.013715237379074097, 0.013675712049007416, 0.03293764963746071, -0.0058003198355436325, -0.0014196126721799374, -0.010961649939417839, -0.008339812979102135, 0.00857037678360939, -0.007397796027362347, -0.0010605923598632216, 0.023991784080863, -0.007384621072560549, 0.01590229757130146, -0.0052930801175534725, -0.02887973003089428, 0.000638990371953696, 0.0027469999622553587, 0.011554527096450329, -0.01340562291443348, -0.020605793222784996, 0.02077706903219223, 0.022516176104545593, 0.00300391367636621, 0.009123728610575199, 0.028642579913139343, -0.0011404660763218999, 0.0023056354839354753, -0.016178973019123077, -0.009150078520178795, 0.01754917949438095, 0.050750330090522766, 0.012509719468653202, -0.005283198785036802, 0.0029742696788161993, -0.018800809979438782, -0.02115914598107338, -0.040078531950712204, 0.022595226764678955, -0.022305376827716827, -0.0036000851541757584, -0.016943126916885376, -0.002906747628003359, 0.019617663696408272, 0.007173819933086634, 0.01915653608739376, 0.012397730723023415, 0.0016509996494278312, -0.006096758879721165, 0.015230368822813034, -0.010665210895240307, -0.00259054615162313, -0.0012483368627727032, -0.007200170308351517, 0.009492630138993263, 0.002348454436287284, -0.029986435547471046, 0.009479455649852753, 0.0014607846969738603, -0.00426213163882494, -0.02247665263712406, 0.012384556233882904, 0.013254109770059586, -0.010269959457218647, 0.005902426782995462, -0.010230434127151966, 0.011640165001153946, 0.0015982994809746742, 0.01442669052630663, 0.023372555151581764, 0.0057048010639846325, 0.007740347646176815, 0.011778503656387329, 0.0013306810287758708, 0.0006612233119085431, 0.014413515105843544, -0.020921994000673294, -0.013023546896874905, 0.010408297181129456, -0.0074373213574290276, 0.0014360814820975065, 0.015744196251034737, 0.007661296986043453, -0.018168406561017036, -0.020210541784763336, 0.008372750133275986, -0.0011981070274487138, -0.0023286917712539434, -0.016442473977804184, -0.0028573409654200077, -0.05140908434987068, -0.021699322387576103, -0.026152493432164192, -0.0021425941959023476, -0.023820508271455765, -0.008972215466201305, -0.023412080481648445, -0.008708714507520199, -0.0053820121102035046, 0.013319985009729862, -0.0041534374468028545, 0.0037087793461978436, -0.0216334480792284, -0.029907384887337685, -0.040473781526088715, 0.0006340497639030218, 0.011890491470694542, 0.015744196251034737, -0.027008872479200363, -0.001105058123357594, -0.003912992775440216, -0.0016246495069935918, -0.007338508032262325, 0.002572430297732353, -0.016363423317670822, -0.013636186718940735, 0.0018395676743239164, 0.002284226007759571, -0.0016789967194199562, -0.0067423367872834206, -0.006445897743105888, 0.03306939825415611, 0.023333029821515083, 0.01878763549029827, -0.0027997002471238375, -0.00560598773881793, -0.006831268314272165, 0.00631744135171175, 0.031119491904973984, -0.00856378860771656, -0.017997130751609802, 0.0037680671084672213, -0.029512133449316025, 0.004749609157443047, -0.00150689750444144, 0.014584790915250778, -0.00408426858484745, 0.01878763549029827, 0.01095506176352501, -0.010026220232248306, 0.0014344346709549427, -0.005556581541895866, -0.009710019454360008, -0.011409602127969265, 0.005237086210399866, 0.030776940286159515, -0.010125033557415009, 0.0023056354839354753, 0.005092160776257515, -0.027061572298407555, -0.0007229814073070884, -0.004245663061738014, -0.0063964915461838245, 0.006139577832072973, 0.01757553033530712, -0.007740347646176815, 0.021304070949554443, -0.0066204676404595375, 0.005820082500576973, -0.013570311479270458, 0.0033596402499824762, -0.007845748215913773, 0.03172554448246956, -0.023003654554486275, -0.011857553385198116, -0.0023237511049956083, -0.01467701606452465, -0.036099664866924286, -0.002860634820535779, -0.009822007268667221, 0.005075691733509302, -0.017417429015040398, 0.004041449632495642, 0.007858922705054283, 0.00032999407267197967, -0.03172554448246956, -0.027114272117614746, -0.02034229226410389, 0.016034048050642014, -0.003264121012762189, 6.602969369851053e-05, 0.0031109610572457314, 0.022634752094745636, -0.017325203865766525, -0.029485784471035004, -0.0023566887248307467, -0.009703431278467178, -0.029881035909056664, 0.02689029648900032, 0.03299035131931305, 0.005115217063575983, 0.0514354333281517, -0.01366253662854433, 0.021330421790480614, 0.003642904106527567, 0.004670558497309685, 0.010118445381522179, 0.013056484051048756, -0.009525568224489689, 7.719761197222397e-05, 0.009044678881764412, 0.01466384157538414, 0.008379338309168816, -0.007779872976243496, 0.011080224998295307, 0.0037548919208347797, 0.021501697599887848, -0.025902166962623596, -0.0009115494322031736, -0.012463606894016266, -0.013912863098084927, -0.014993217773735523, 0.0033398775849491358, -0.010915537364780903, 0.016574224457144737, -0.025164363905787468, -0.008708714507520199, -0.0074109709821641445, 0.0027140623424202204, 0.02075071819126606, 0.007990674115717411, 0.00974295660853386, -0.00034152224543504417, 0.01408413890749216, 0.011640165001153946, -9.382083226228133e-05, -0.010869423858821392, -0.002457148628309369, -0.0061132279224693775, 0.002211763057857752, 0.023886382579803467, 0.010151383467018604, 0.03217349573969841, -0.013451735489070415, 0.017812680453062057, 0.018576834350824356, 0.007081594783812761, -0.011350314132869244, -0.017746806144714355, 0.015401644632220268, -0.011034112423658371, -0.016126273199915886, -0.05992017313838005, -0.06144847720861435, -0.028405427932739258, -0.001559597672894597, 0.02069801837205887, -0.017720455303788185, 0.009387229569256306, 0.003038498107343912, -0.015968171879649162, -0.01752282865345478, 0.01873493567109108, 0.045770157128572464, 0.0004965350381098688, 0.016547875478863716, 0.014018263667821884, -0.00147395976819098, -0.003619847586378455, 0.02732507325708866, -0.00672257412225008, 0.007292395457625389, 0.029459433630108833, 0.006179103162139654, -0.008175124414265156, -0.012285742908716202, -0.008649426512420177, -0.007292395457625389, -0.0017934549832716584, -0.02247665263712406, 0.015507045201957226, 0.004937353543937206, -0.02604709379374981, 0.013063071295619011, -0.0077601103112101555, -0.028642579913139343, -0.0020684844348579645, -0.03019723668694496, -0.012904970906674862, -0.018629534170031548, -0.002987444866448641, -0.028194628655910492, 0.030223587527871132, -0.011600639671087265, 0.02359653264284134, -0.010526872240006924, -0.00038372361450456083, -0.015032743103802204, -0.0017341672210022807, 0.014413515105843544, -0.001657587243244052, 0.020210541784763336, 0.02490086294710636, -0.009057853370904922, 0.005941952113062143, 0.017786331474781036, -0.013952388428151608, -0.000989776337519288, 0.02156757190823555, -0.011640165001153946, 0.027562225237488747, -0.010869423858821392, -0.017377903684973717, 0.006735749077051878, 0.013148709200322628, 0.0063108536414802074, -0.00978248193860054, 0.004295069258660078, -0.01878763549029827, -0.001961437053978443, -0.016455650329589844, 0.021317247301340103, -0.009413580410182476, -0.0026284244377166033, 0.0010927064577117562, -0.013741587288677692, 0.01548069529235363, 0.004334594588726759, -0.013833812437951565, -0.002858988009393215, -0.027430474758148193, 0.0010721205035224557, -0.007048657163977623, 0.010856249369680882, 0.033596403896808624, -0.008939278312027454, -0.00878776516765356, -0.0015167787205427885, 0.041343338787555695, -0.014953692443668842, -0.0015727727441117167, 0.025493741035461426, 0.010546634905040264, -0.012417493388056755, -0.0067785680294036865, 0.019723065197467804, -0.023451605811715126, 0.008372750133275986, -0.0049735852517187595, 0.008504500612616539, -0.006202159449458122, -0.0017391078872606158, 0.0005496470257639885, -0.005220617633312941, -0.0065315356478095055, -0.00936087965965271, -0.004143556114286184, 0.013636186718940735, -0.013306810520589352, -0.011080224998295307, 0.0014509034808725119, 0.000713923538569361, 0.019683539867401123, 0.019788939505815506, -0.016429299488663673, 0.00310766720212996, -0.0007966794073581696, -0.012779807671904564, -0.0030615543946623802, -0.03501930832862854, -0.004640914965420961, 0.015731021761894226, 0.015388470143079758, -0.00275029381737113, -0.018128881230950356, -0.0219496488571167, -0.01667962595820427, -0.009459692984819412, 0.018893035128712654, -0.003586909966543317, -0.00878117699176073, 0.009255479089915752, 0.009881294332444668, 0.010269959457218647, -0.011047287844121456, -0.026231544092297554, -0.01621849834918976, 0.005474237259477377, -0.005349074024707079, -0.02735142409801483, -0.0008473210036754608, -0.014518915675580502, 0.013293635100126266, 0.008300287649035454, -0.031119491904973984, -0.015770547091960907, 0.00325753353536129, -0.03633681312203407, -0.020263241603970528, -0.007990674115717411, -0.019894341006875038, 0.008497913368046284, 0.026336943730711937, 0.009420167654752731, 0.013570311479270458, 0.0052963742054998875, 0.025414690375328064, -0.020276416093111038, 0.0036264352966099977, 0.007167232688516378, -0.02002609148621559, -0.00037734193028882146, 0.021093269810080528, -0.0166532751172781, -0.0033892840147018433, -0.002786525059491396, 0.001875799149274826, 0.010770611464977264, 0.025862641632556915, -0.009400404989719391, -0.004766077734529972, 0.0024867926258593798, -0.003889936488121748, 0.011706040240824223, 0.015309419482946396, 0.017298853024840355, -0.013702061958611012, 0.008451800793409348, -0.005859607830643654, 0.015744196251034737, 0.003008854342624545, 0.00652494840323925, 0.018194757401943207, 0.0022825791966170073, 0.01245043147355318, -0.01703535206615925, 0.005474237259477377, -0.010928711853921413, -0.0012022241717204452, 0.014795592054724693, -0.009248891845345497, -0.0186954103410244, 0.02727237343788147, 0.011666514910757542, -0.010329246520996094, -0.002676184056326747, 0.009018328040838242, -0.016771851107478142, -0.02972293458878994, -0.00010776786803035066, -0.026705846190452576, -0.014545265585184097, -0.03378085419535637, 0.010520284995436668, -0.023095879703760147, 0.007154057268053293, 0.015177669003605843, -0.002537845866754651, -0.00936746783554554, 0.016903601586818695, 0.000287792703602463, -0.03217349573969841, -0.005204148590564728, -0.02200235053896904, 0.00791162345558405, -0.03783877193927765, -0.0032888243440538645, -0.002532905200496316, 0.009117141366004944, 0.0013767937198281288, -0.00012166344095021486, -0.014597966335713863, -0.0011009409790858626, 0.016916776075959206, 0.020250067114830017, 0.00530625507235527, 0.02367558144032955, 0.2160709798336029, -0.02276650257408619, -0.0006303442642092705, 0.02002609148621559, -0.0032278895378112793, 0.0007781519670970738, 5.9236303059151396e-05, 0.0039064050652086735, -0.018655885010957718, -0.010006457567214966, 0.01490099262446165, 0.00020102258713450283, -0.002387979533523321, -0.003619847586378455, 0.0035539723467081785, -0.024650536477565765, -0.005912308115512133, -0.01789173111319542, -0.027957476675510406, -0.015190843492746353, -0.00509874802082777, -0.019802113994956017, -0.0024126828648149967, -0.0186954103410244, 0.013675712049007416, 6.633848533965647e-05, 0.0033761090599000454, 0.00016396773571614176, 0.010836486704647541, 0.034018002450466156, -0.005125098396092653, 0.00022232913761399686, 0.017232978716492653, -0.003481509629637003, -0.01179167814552784, -0.003735129488632083, 0.01590229757130146, 0.00018434791127219796, 0.027799375355243683, 0.016034048050642014, 0.03148839250206947, -0.020144665613770485, 0.0035144472494721413, -0.002715709153562784, 0.00793138612061739, 0.0024900862481445074, -0.021725673228502274, -0.008623076602816582, -0.009861532598733902, 0.03507201001048088, 0.0066171735525131226, -0.00457174563780427, 0.015204018913209438, 0.018603185191750526, -0.008175124414265156, -0.005566462874412537, -0.0004957116325385869, 0.017430603504180908, 0.02445291168987751, -0.006044058594852686, 0.01442669052630663, 0.027509525418281555, 0.0026663027238100767, 0.005780557636171579, -0.010296309366822243, 0.020434517413377762, -0.031198540702462196, 0.021264545619487762, 0.0016040635528042912, -0.01099458709359169, 0.0035012720618396997, -0.009314767085015774, -0.0024143296759575605, -0.005006522871553898, -0.029248632490634918, -0.022674277424812317, 0.03617871552705765, 0.019288286566734314, 0.02885338105261326, 0.016442473977804184, -0.0065216547809541225, -0.010125033557415009, -0.010316072031855583, -0.012951083481311798, -0.04276624321937561, -0.049643624573946, 0.021857423707842827, -0.02276650257408619, 0.004331300966441631, -0.023991784080863, 0.007878685370087624, 0.0009444871102459729, -0.0017358141485601664, -0.011113163083791733, 0.008049961179494858, 0.011020937003195286, 0.005260142497718334, 0.020144665613770485, -0.010592748410999775, 0.00427201297134161, -0.019762588664889336, 0.01504591852426529, 0.02727237343788147, -0.0047627841122448444, -0.014268589206039906, 0.013715237379074097, -0.011692865751683712, -0.011146100237965584, 0.006264741066843271, -0.011389839462935925, -0.019630838185548782, -0.025875817984342575, 0.0020783657673746347, -0.016850901767611504, -0.00796432327479124, 0.012911558151245117, 0.025401515886187553, -0.015032743103802204, 0.018418733030557632, -0.020856119692325592, -0.027509525418281555, -0.02030276693403721, -0.0002952036738861352, 0.01320799719542265, -0.0026333651039749384, -0.008682364597916603, -0.012951083481311798, 0.00793138612061739, -0.012265980243682861, -0.012542656622827053, 0.02808922715485096, 0.002951213391497731, 0.02197599969804287, 0.011099987663328648, -0.017022177577018738, 0.038075923919677734, 0.011132925748825073, 0.01918288692831993, -0.010144796222448349, 0.026587270200252533, 0.010474172420799732, -0.023043179884552956, 0.006669873837381601, -0.00854402594268322, -0.010447822511196136, -0.028273677453398705, 0.013543961569666862, 0.006001239642500877, 0.00025073785218410194, -0.03133029118180275, -0.025309288874268532, -0.009018328040838242, -0.008576964028179646, -0.008978803642094135, 0.027483174577355385, -0.018458258360624313, 0.0015513632679358125, -0.04845786839723587, -0.020566267892718315, 0.008076312020421028, -0.02930133230984211, -0.0012680995278060436, 0.008135599084198475, -0.035678062587976456, -0.014940517954528332, -0.006508479360491037, -0.1701163649559021, 0.00957826804369688, 0.0028013470582664013, -0.02808922715485096, -0.0033859903924167156, 0.0158891212195158, 0.004370825830847025, 0.003922874107956886, -0.013807462528347969, -0.002106362720951438, 0.01918288692831993, -0.010908949188888073, -0.031040441244840622, -0.012773220427334309, -0.006465660408139229, 0.018010307103395462, -0.010731086134910583, -0.022911429405212402, 0.04226559028029442, 0.010698148049414158, 0.030355338007211685, -0.03549361228942871, 0.014150014147162437, -0.006989369168877602, 0.0005512938951142132, 0.006093465257436037, -0.0013430326944217086, 0.032779548317193985, -0.0043411822989583015, -0.00046647945418953896, 0.010717910714447498, -0.028247328475117683, 0.03454500809311867, -0.004934059921652079, 0.012773220427334309, 0.015032743103802204, 0.02362288162112236, -0.021883774548768997, -0.00489124096930027, 0.01594182290136814, 0.02603391744196415, -0.0026844183448702097, -0.017206627875566483, 0.0064327227883040905, 0.003028616774827242, 0.012951083481311798, 0.022608403116464615, -0.008076312020421028, 0.027483174577355385, -0.0013158590300008655, 0.005652100779116154, -0.019275112077593803, 0.01142936386168003, 0.001468195696361363, 0.010006457567214966, 0.018958911299705505, 0.007773285266011953, 0.018945734947919846, 0.014558441005647182, -0.005405068397521973, 0.02523024007678032, -0.03472945839166641, -0.011086813174188137, -0.02727237343788147, -0.021014221012592316, -0.028431778773665428, -0.020223716273903847, 0.0066566988825798035, -0.002020724816247821, 0.005177798680961132, -0.01625802367925644, 0.002862281631678343, 0.006485423073172569, -0.007292395457625389, -0.004868184681981802, 0.02766762487590313, -0.013688887469470501, 0.02283237874507904, 0.0036066726315766573, -0.013636186718940735, -0.0018033363157883286, 0.029564833268523216, -0.002205175580456853, 0.0036363163962960243, 0.0033234087750315666, -0.019077487289905548, 0.0011231738608330488, -0.0020009621512144804, -0.022924603894352913, -0.012246217578649521, 0.013056484051048756, -0.05009157583117485, -0.002378098201006651, -0.016178973019123077, 0.012918146327137947, 0.02649504505097866, 0.0013496201718226075, -0.0012244570534676313, -0.0022364663891494274, -0.014611140824854374, -0.020157841965556145, -0.005981476977467537, -0.010704736225306988, 0.020052440464496613, 0.031119491904973984, 0.003031910629943013, 0.0075097838416695595, -0.005085573066025972, 0.0553879514336586, -0.0035934974439442158, -0.010790374130010605, -0.008445213548839092, 0.018471432849764824, 0.015322593972086906, 0.011673103086650372, 0.03414975479245186, -0.00938064232468605, -0.015968171879649162, 0.01586277224123478, 0.0036692540161311626, 0.05665275827050209, 0.013820637948811054, -0.02397860772907734, 0.021277721971273422, -0.004855009727180004, -0.02488768845796585, -0.10039395838975906, -0.016047222539782524, 0.018194757401943207, 0.012463606894016266, -0.013148709200322628, 0.022081399336457253, 0.0009988342644646764, 0.0012557478621602058, -0.025757241994142532, 0.022937778383493423, -0.007937973365187645, -0.04853691905736923, -0.01466384157538414, -0.009071028791368008, -0.004930766299366951, 0.004512458108365536, 0.011732391081750393, 0.010770611464977264, -0.017377903684973717, 0.030645187944173813, 0.001099294051527977, -0.002774996915832162, 0.024097183719277382, -0.01548069529235363, -0.0005858784425072372, 0.013939213007688522, -0.022081399336457253, -0.0036857230588793755, 0.011541352607309818, -0.005691625643521547, 0.008161949925124645, -0.027509525418281555, -0.0003293764893896878, -0.020553093403577805, 0.0038932301104068756, -0.007358270697295666, -0.0018263926031067967, 0.0036988980136811733, 0.02285872772336006, -0.042502742260694504, 0.004568452015519142, -0.029090531170368195, -0.01591547206044197, -0.015572920441627502, -0.0005039460374973714, 0.0174833033233881, -0.007147470023483038, 0.00046771462075412273, 0.0223976019769907, -0.015586095862090588, -0.026784896850585938, -0.01283250842243433, -0.024676887318491936, -0.0016592340543866158, 0.03059248812496662, 0.011409602127969265, 0.00427201297134161, -0.011903666891157627, -0.010678386315703392, 0.003840529825538397, -0.0272460225969553, -0.005777263548225164, -0.027008872479200363, 0.009136904031038284, 0.010026220232248306, -0.004351063631474972, -0.02001291513442993, -0.014914167113602161, -0.003275649156421423, -0.0022298789117485285, -0.016152624040842056, 0.012127642519772053, -0.013873337768018246, 0.027430474758148193, -0.033227499574422836, 0.0022875196300446987, -0.016099922358989716, -0.01594182290136814, 0.020487217232584953, -0.009617793373763561, -0.021725673228502274, -0.01447939034551382, 0.01715392805635929, -0.019828464835882187, -0.0025526678655296564, 0.021896949037909508, -0.010171146132051945, 0.013438560999929905, -0.008372750133275986, -0.03710096701979637, -0.01239114347845316, 0.01097482442855835, 0.026376469060778618, -0.03130394220352173, -0.012239630334079266, 0.009169841185212135, -0.012898383662104607, -0.004835247062146664, 0.02523024007678032, 0.01404461357742548, -0.024347510188817978, 0.0012886854819953442, -0.054333947598934174, 0.004235781729221344, -0.00396239897236228, -0.021646622568368912, -0.0018346270080655813, -0.024597836658358574, -0.020039265975356102, -0.002203528769314289, 0.0016197089571505785, 0.01997338980436325, 0.0038471175357699394, 0.0024555018171668053, 0.0028046409133821726, 0.010704736225306988, -0.01595499739050865, -0.023451605811715126, 0.02191012352705002, -0.00300391367636621, 0.004532220307737589, 0.025836292654275894, -0.009591443464159966, -0.00999987032264471, 0.004815484397113323, 0.018168406561017036, 0.0045025767758488655, -8.337342296727002e-05, -0.01442669052630663, 0.013926038518548012, -0.021422646939754486, -0.009532155469059944, 0.0012063414324074984, -0.04184398800134659, -0.008636252023279667, 0.028616229072213173, 0.0007526252884417772, -0.022661102935671806, 0.024097183719277382, 0.015586095862090588, 0.033253852277994156, 0.01948591321706772, -0.012727107852697372, -0.02487451210618019, 0.02039499208331108, 0.009301592595875263, -0.005059222690761089, 0.012437256053090096, -0.01326728519052267, -0.002625130582600832, 0.01509861834347248, 0.00792479794472456, 0.022608403116464615, 0.011067050509154797, -0.011271263472735882, 0.009288417175412178, -0.005635631736367941, 0.0017374609597027302, 0.026205193251371384, -0.0021607098169624805, -0.002083306200802326, -0.027430474758148193, 0.04961727559566498, 0.01631072349846363, 0.009031503461301327, -0.005141566973179579, 0.008833877742290497, 0.010125033557415009, -0.016943126916885376, 0.011146100237965584, 0.011370076797902584, -0.0009403699077665806, -0.018010307103395462, 0.012489956803619862, 0.005573050118982792, 0.002053662436082959, 0.008886577561497688, 0.004117206204682589, 0.015177669003605843, -0.0016394715057685971, -0.02237125113606453, 0.033148448914289474, 0.007569071836769581, -0.011172451078891754, -0.00954533088952303, 0.008906340226531029, 0.013352923095226288, 0.026205193251371384, 0.0008102661813609302, 0.011528177186846733, -0.0052930801175534725, -0.0013479732442647219, -0.015138143673539162, -0.0015274834586307406, 0.013517611660063267, -0.0028128752019256353, -0.013379273004829884, 0.004235781729221344, 0.006037470884621143, 0.027614925056695938, 0.030012786388397217, 0.02569136582314968, 0.036521267145872116, 0.003665960393846035, -0.017246153205633163, -0.042950693517923355, -0.020091965794563293, 0.01785220578312874, 0.004380707163363695, -0.03246334567666054, -0.00040719169192016125, 0.009644143283367157, 0.010072332806885242, 0.0005335899186320603, -0.03335925191640854, 0.004693614784628153, -0.020474042743444443, -0.013636186718940735, -0.009677081368863583, -0.01706170290708542, -0.03175189346075058, 0.021896949037909508, -0.0072265202179551125, 0.030776940286159515, 0.012555832043290138, 0.013781112618744373, 0.0187612846493721, -0.004051330965012312, -0.01142936386168003, -0.012167167849838734, 0.013873337768018246, -0.004604683257639408, -0.0044762264005839825, 0.005121804308146238, -0.008860227651894093, 0.002192000625655055, -0.02204187400639057, 0.021409472450613976, -0.017601879313588142, 0.015111793763935566, 0.006916906218975782, 0.06735090166330338, -0.007233107928186655, -0.014624316245317459, 0.021277721971273422, -0.022687451913952827, 0.018484609201550484, 0.01839238405227661, 0.0036000851541757584, -0.038471173495054245, -0.018115706741809845, 0.008517676033079624, -0.00010437117452966049, -0.006541416980326176, -0.02607344277203083, -0.012463606894016266, -0.0038800551556050777, 0.00979565642774105, 0.0030022666323930025, -0.019472738727927208, 0.01674550026655197, 0.02073754370212555, 0.02357018180191517, 0.017351552844047546, 0.00876800250262022, -0.01666644960641861, 0.008517676033079624, 0.029960086569190025, -0.019261937588453293, -0.02119867131114006, -0.011864141561090946, 0.007845748215913773, -0.011976129375398159, -0.051540832966566086, -0.01443986501544714, 0.009973520413041115, -0.01280615758150816, -0.0071145324036479, -0.010171146132051945, 0.00754930917173624, 0.030065486207604408, 0.020539918914437294, 0.041290637105703354, -0.024769112467765808, -0.008049961179494858, 0.033201150596141815, 0.008471563458442688, -0.008616489358246326, -0.017193453386425972, -0.03346465155482292]\n"
          ]
        }
      ],
      "source": [
        "def create_embedding(prompt: str, model=\"text-embedding-ada-002\") -> list[float]:\n",
        "    return client.embeddings.create(model=model, input=prompt).data[0].embedding\n",
        "\n",
        "print(create_embedding(\"This is an embedding!\"))\n",
        "\n",
        "database: list[list[list[float]], str] = []\n",
        "\n",
        "# Create embedding-text key-value pairs and add them to the database\n",
        "corresponding_text_1 = \"This is an embedding!\"\n",
        "embedding_1 = create_embedding(corresponding_text_1)\n",
        "database.append([embedding_1, corresponding_text_1])\n",
        "\n",
        "corresponding_text_2 = \"Sverre is CTO of Cogito NTNU\"\n",
        "embedding_2 = create_embedding(corresponding_text_2)\n",
        "database.append([embedding_2, corresponding_text_2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "dfi_Eg6FUB7D",
        "outputId": "cb242f3d-ae12-4e37-cbdb-658b257bdfa2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(0.8882390742588276, 'Sverre is CTO of Cogito NTNU')]"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "def cosine_similarity(a: list[float], b: list[float]) -> float:\n",
        "    \"\"\"\n",
        "    Takes 2 vectors a, b and finds how similar they are using the cosine similarity\n",
        "\n",
        "    Args:\n",
        "    a (list[float]): A list of floats\n",
        "    b (list[float]): A list of floats\n",
        "\n",
        "    Returns:\n",
        "        The similarity of the two vectors a and b described as a float between 0 and 1\n",
        "\n",
        "    \"\"\"\n",
        "    return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))\n",
        "\n",
        "def search_docs(query: str, database: list[list[list[float]], str], top_k: int=1):\n",
        "    \"\"\"\n",
        "    Searches the database for the most similar documents to the query\n",
        "\n",
        "    Args:\n",
        "        query (str): The query to search for\n",
        "        database (list[list[list[float]], str]): The database to search in\n",
        "        top_k (int): The number of documents to return\n",
        "    Returns:\n",
        "        A list of the top_k most similar documents to the query\n",
        "    \"\"\"\n",
        "    query_embedding = create_embedding(query)\n",
        "    results = []\n",
        "    for (doc_embedding, doc) in database:\n",
        "        similarity = cosine_similarity(query_embedding, doc_embedding)\n",
        "        results.append((similarity, doc))\n",
        "    return sorted(results, reverse=True)[:top_k]\n",
        "\n",
        "search_docs(\"Who is the CTO of Cogito?\", database)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V4yWzB9s9caE"
      },
      "source": [
        "### **Task 4.1**\n",
        "*Create a new embedding with some text of your choice, and add it to the database. See if you can make the model find it.*\n",
        "\n",
        "<details>\n",
        "    <summary><strong>Hint:</strong></summary>\n",
        "      - Look at the previous two cells\n",
        "</details>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "g-1zWV3u--Ih",
        "outputId": "3ecefe23-a696-4de1-edc6-5f3cacc0ee53",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "What would you like to ask the model: who are you?\n",
            "The AI gave the answer: [(0.759581346207335, 'This is an embedding!')]\n",
            "\n",
            "What would you like to ask the model: who's steve?\n",
            "The AI gave the answer: [(0.7443181673040701, 'Sverre is CTO of Cogito NTNU')]\n",
            "\n",
            "What would you like to ask the model: who's sverre?\n",
            "The AI gave the answer: [(0.8542858374675332, 'Sverre is CTO of Cogito NTNU')]\n",
            "\n",
            "What would you like to ask the model: who is the CTO of Cogito?\n",
            "The AI gave the answer: [(0.8827274723061123, 'Sverre is CTO of Cogito NTNU')]\n",
            "\n",
            "What would you like to ask the model: Is Sverre the CTO of Cogito NTNU?\n",
            "The AI gave the answer: [(0.9655346642530646, 'Sverre is CTO of Cogito NTNU')]\n",
            "\n",
            "What would you like to ask the model: Are you the CTO?\n",
            "The AI gave the answer: [(0.8220509357827853, 'Sverre is CTO of Cogito NTNU')]\n",
            "\n",
            "What would you like to ask the model: Are cats and dogs the same?\n",
            "The AI gave the answer: [(0.7517455434144434, 'This is an embedding!')]\n",
            "\n",
            "What would you like to ask the model: smarty pants\n",
            "The AI gave the answer: [(0.7608779511666223, 'This is an embedding!')]\n",
            "\n",
            "What would you like to ask the model: q\n",
            "[SUCCESS] Shut down\n"
          ]
        }
      ],
      "source": [
        "# TODO: Create an embedding for some text and append it to the database\n",
        "\n",
        "while True:\n",
        "  user_input: str = input(\"What would you like to ask the model: \")\n",
        "\n",
        "  if user_input == \"q\":\n",
        "      print(\"[SUCCESS] Shut down\")\n",
        "      break\n",
        "\n",
        "  answer = search_docs(user_input, database, top_k=1)\n",
        "\n",
        "  print(f\"The AI gave the answer: {answer}\\n\")\n",
        "\n",
        "new_embedding = create_embedding(user_input)\n",
        "database.append([new_embedding, user_input])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ExQMSdXYSyVe"
      },
      "source": [
        "#### Task 5.2\n",
        "*Work together with others and create something cool, try to utilize the different lesseons you have learned examples are:*\n",
        "* Create external API access some live data\n",
        "* Create more complex math operations to do calculus\n",
        "* Create bash scripts to create folders or organize a folder\n",
        "* Access a database for getting info\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "6ClLpQnGTlcX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "28fffc57-dc03-461b-c9dc-77c6158da08d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The ten least valuable crypto currencies are as follows:\n",
            "\n",
            "1. Pinkcoin (PINK)\n",
            "2. ZENZO (ZNZ)\n",
            "3. Indorse Token (IND)\n",
            "4. Swace (SWACE)\n",
            "5. Bitcoin Atom (BCA)\n",
            "6. ZCore (ZCR)\n",
            "7. Bispex (BPX)\n",
            "8. Kryptofranc (KYF)\n",
            "9. DopeCoin (DOPE)\n",
            "10. Asch (XAS)\n"
          ]
        }
      ],
      "source": [
        "prompt_crypto = \"\"\"\n",
        "You are a crypto expert looking for good investments.\n",
        "Check https://coinmarketcap.com/ to gather relevant information about different crypto currency.\n",
        "\n",
        "\n",
        "Samples\n",
        "\n",
        "Question: What is the most valuable crypto currency?\n",
        "Answer: The most valuable Crypto currency  is {name}\n",
        "        It has a value of {value}\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "question = \"What are the ten least valuable crypto currencies?\"\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "    model = MODEL_NAME,\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": prompt_crypto},\n",
        "        {\"role\": \"user\", \"content\": question}\n",
        "    ]\n",
        ")\n",
        "\n",
        "print(response.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Coyz5uZE1vYd"
      },
      "source": [
        "\n",
        "### Running local LLMs\n",
        "For those interested in experimenting with Large Language Models (LLMs) without incurring the costs associated with API calls to services like OpenAI's, or dealing with sensitive or proprietary data, running pre-trained models on your own hardware presents a viable alternative. The open-source community, particularly [Hugging Face's](https://huggingface.co/models) Transformers library, offers access to a wide range of models, including some developed by leading tech companies.\n",
        "\n",
        "One of the standout models available is Google's FLAN-T5-XL, part of the T5 (Text-to-Text Transfer Transformer) family, which has been fine-tuned for a broad set of tasks. This model combines the flexibility of T5's architecture with training on a mixture of supervised and unsupervised tasks, making it particularly adept at understanding and generating human-like text.\n",
        "\n",
        "To get started with using FLAN-T5-XL or any other model from the Transformers library, you will need to install the necessary packages and understand how to load and interact with the model. Below is a basic Python script that demonstrates how to set up and use FLAN-T5-XL for generating text based on input prompts:\n",
        "```python\n",
        "import sys\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, GenerationConfig\n",
        "\n",
        "line = 'What is the value of being accepted into Cogito NTNU, Norway's largest technical AI student organisation, in the middle of an AI revolution?'\n",
        "\n",
        "model_name = 'google/flan-t5-xl'\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
        "\n",
        "config = GenerationConfig(max_new_tokens=200)\n",
        "for line in sys.stdin:\n",
        "    tokens = tokenizer(line, return_tensors=\"pt\")\n",
        "    outputs = model.generate(**tokens, generation_config=config)\n",
        "    print(tokenizer.batch_decode(outputs, skip_special_tokens=True))\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l3nKpepS9Xmw"
      },
      "source": [
        "### Context windows\n",
        "\n",
        "The context window refers to the maximum amount of text (measured in tokens) the model can consider at one time when generating responses or performing tasks. This limit is intrinsic to the model's architecture and significantly influences how we design prompts and interpret model outputs.\n",
        "\n",
        "#### Significance of the Context Window\n",
        "The size of the context window determines how much information the model can \"see\" and use at any given moment. For example, GPT-3 has a context window of 2048 tokens. This means it can consider up to 2048 tokens of preceding text to generate its responses. The implications are twofold:\n",
        "\n",
        "* **Prompt Design:** When crafting prompts for an LLM, it's vital to ensure that the most relevant information is within the model's context window. Information beyond this limit won't influence the model's output, emphasizing the need for concise and focused prompt design.\n",
        "\n",
        "* **Sequential Tasks:** For tasks requiring more information than the context window allows, you may need to design a series of prompts that build on each other, ensuring each segment of the task remains within the model's view.\n",
        "\n",
        "While advancements have led to models supporting context windows surpassing 100,000 tokens (gpt-4 and other open source ones), challenges persist. Specifically, such models tend to focus on the beginning and end of the provided text, potentially underutilizing the middle portion. This is know as [lost in the middle](https://arxiv.org/pdf/2307.03172.pdf).\n",
        "\n",
        "#### New insights by a Operative System inspired model\n",
        "[MemGPT](https://memgpt.readme.io/docs/index) introduces a strategic approach to memory management, organized around two core concepts relevant to understanding context windows in LLMs:\n",
        "\n",
        "* **Memory Hierarchy:** It segments memory into two types: a \"main context\" analogous to RAM, which is smaller and faster, and an \"external context\" similar to disk storage, which is larger but slower. This structure necessitates the deliberate transfer of information between these contexts, using virtual memory.\n",
        "\n",
        "* **Process Management:** Similar to an operating system's role in managing tasks, MemGPT regulates the flow of information between the memory segments, the LLM, and users, ensuring efficient handling of processes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oc8BDSKT1y-C"
      },
      "source": [
        "### Fine-tuning Large Language Models\n",
        "Fine-tuning is a process that adjusts a pre-trained model to a specific task or dataset, enhancing its ability to perform on tasks it wasn't specifically trained for initially. This method leverages the general understanding that the model has developed during its initial training phase, applying it to a more focused domain or problem set. Fine-tuning can significantly improve the performance of LLMs on specialized tasks, making it a powerful tool for developers and researchers.\n",
        "\n",
        "#### Why Fine-tune?\n",
        "Customization: Tailors the model to understand and generate responses based on specific jargon, styles, or formats unique to your dataset.\n",
        "Improved Performance: Enhances the model's accuracy and efficiency on tasks that may differ from the data it was originally trained on.\n",
        "Cost-Effectiveness: Utilizes the foundational knowledge the model has gained, reducing the need for training from scratch on vast datasets.\n",
        "\n",
        "1. **How to Fine-tune an LLM:**\n",
        "Select a Pre-trained Model: Choose a model that closely aligns with your task in terms of language and domain. Models available on platforms like Hugging Face offer a good starting point.\n",
        "\n",
        "2. **Prepare Your Dataset:** Your dataset should be representative of the task at hand and formatted in a way that the model can understand. It typically involves splitting the data into training, validation, and test sets.\n",
        "\n",
        "3. **Customize Training Parameters:** Adjust parameters such as learning rate, batch size, and the number of epochs to balance between retaining learned knowledge and adapting to the new dataset.\n",
        "\n",
        "4. **Train the Model:** Use a suitable environment and framework, like PyTorch or TensorFlow, along with Hugging Face's Transformers library, to fine-tune the model on your dataset.\n",
        "\n",
        "5. **Evaluate and Iterate:** Test the model's performance on a separate validation set, and iteratively adjust your approach based on the results.\n",
        "\n",
        "An example of this using OpenAI can be found in the Cogito Project [MarketingAI](https://github.com/CogitoNTNU/MarketingAI/blob/main/src/fine_tuning/fine_tuning_job.py)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ht-CtKNT7w8v"
      },
      "source": [
        "### Leveraging OpenAI Across Diverse Programming Environments\n",
        "While this course primarily focuses on Python to interact with OpenAI's models. Thera are other supported languages. Supported languages include, but are not limited to, TypeScript/JavaScript, Java, C#, Go, C++, and PHP, alongside others like Clojure, Kotlin, Ruby, Rust, and Scala. This wide-ranging support extends the potential of OpenAI's AI models to virtually any software development domain, from web development and mobile applications to enterprise solutions and beyond.\n",
        "\n",
        "[Read more at OpenAI Docs](https://platform.openai.com/docs/libraries/community-libraries)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}